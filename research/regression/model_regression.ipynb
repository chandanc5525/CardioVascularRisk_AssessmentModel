{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b36f4996",
      "metadata": {
        "id": "b36f4996"
      },
      "outputs": [],
      "source": [
        "# Importing Data Manipulation Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import Data Visualization Libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Import Filter Warning Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# Import Logging\n",
        "import logging\n",
        "logging.basicConfig(level = logging.INFO,\n",
        "                    format = '%(asctime)s - %(levelname)s - %(message)s',\n",
        "                    filemode = 'w',\n",
        "                    filename = 'model.log',force = True)\n",
        "# Import Scikit Learn Libraries for Machine Learning Model Building\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,learning_curve,KFold\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "import xgboost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Multicolinearity test and treatment libraries\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.decomposition import PCA\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "51ab62fa",
      "metadata": {
        "id": "51ab62fa"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "def data_ingestion(data_source: str) -> pd.DataFrame:\n",
        "\n",
        "    logging.info(\"Data Ingestion Started...\")\n",
        "    df = pd.read_csv(data_source)\n",
        "    logging.info(\"Data Ingestion Completed Successfully\")\n",
        "    return df\n",
        "\n",
        "def data_exploration(df: pd.DataFrame) -> pd.DataFrame:\n",
        "\n",
        "    stats = []\n",
        "\n",
        "    numerical_cols = df.select_dtypes(exclude='object').columns\n",
        "\n",
        "    for col in numerical_cols:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        LW = Q1 - 1.5 * IQR\n",
        "        UW = Q3 + 1.5 * IQR\n",
        "\n",
        "        outlier_flag = \"Has Outliers\" if df[(df[col] < LW) | (df[col] > UW)].shape[0] > 0 else \"No Outliers\"\n",
        "\n",
        "        numerical_stats = OrderedDict({\n",
        "            \"Feature\": col,\n",
        "            \"Minimum\": df[col].min(),\n",
        "            \"Maximum\": df[col].max(),\n",
        "            \"Mean\": df[col].mean(),\n",
        "            \"Median\": df[col].median(),\n",
        "            \"Mode\": df[col].mode().iloc[0] if not df[col].mode().empty else np.nan,\n",
        "            \"25%\": Q1,\n",
        "            \"75%\": Q3,\n",
        "            \"IQR\": IQR,\n",
        "            \"Standard Deviation\": df[col].std(),\n",
        "            \"Skewness\": df[col].skew(),\n",
        "            \"Kurtosis\": df[col].kurt(),\n",
        "            \"Outlier Comment\": outlier_flag\n",
        "        })\n",
        "\n",
        "        stats.append(numerical_stats)\n",
        "\n",
        "    report = pd.DataFrame(stats)\n",
        "    return report\n",
        "\n",
        "def categorical_summary(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cat_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "    summary = []\n",
        "    for col in cat_cols:\n",
        "        summary.append({\n",
        "            \"Feature\": col,\n",
        "            \"Unique Values\": df[col].nunique(),\n",
        "            \"Most Frequent\": df[col].mode().iloc[0] if not df[col].mode().empty else None,\n",
        "            \"Missing Values\": df[col].isna().sum()\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "def split_data(data, target_col, test_size=0.3, random_state=42):\n",
        "    X = data.drop(columns=[target_col])\n",
        "    y = data[target_col]\n",
        "\n",
        "    return train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "\n",
        "def encode_categorical(X_train, X_test):\n",
        "    X_train = X_train.copy()\n",
        "    X_test = X_test.copy()\n",
        "\n",
        "    cat_cols = X_train.select_dtypes(include=\"object\").columns\n",
        "\n",
        "    encoders = {}\n",
        "\n",
        "    for col in cat_cols:\n",
        "        le = LabelEncoder()\n",
        "\n",
        "        # Fit ONLY on train\n",
        "        X_train[col] = le.fit_transform(X_train[col])\n",
        "\n",
        "        # Transform test using same mapping\n",
        "        X_test[col] = X_test[col].map(\n",
        "            lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
        "        )\n",
        "\n",
        "        encoders[col] = le\n",
        "\n",
        "    return X_train, X_test, encoders\n",
        "\n",
        "def train_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    return rmse, r2\n",
        "def compare_models(X_train, X_test, y_train, y_test):\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Lasso\": Lasso(),\n",
        "        \"Ridge\": Ridge(),\n",
        "        \"Decision Tree\": DecisionTreeRegressor(),\n",
        "        \"SVR\": SVR(),\n",
        "        \"KNN\": KNeighborsRegressor(),\n",
        "        \"Random Forest\": RandomForestRegressor(),\n",
        "        \"Gradient Boost\": GradientBoostingRegressor(),\n",
        "        \"Ada Boost\": AdaBoostRegressor(),\n",
        "        \"XG Boost\": XGBRegressor()\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        rmse, r2 = train_evaluate_model(\n",
        "            model, X_train, X_test, y_train, y_test\n",
        "        )\n",
        "        results.append([name, rmse, r2])\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        results, columns=[\"Model Name\", \"RMSE\", \"R2 Score\"]).sort_values(\"R2 Score\", ascending=False)\n",
        "\n",
        "def k_fold_cv(X_train, y_train, folds=10):\n",
        "    models = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Lasso\": Lasso(),\n",
        "        \"Ridge\": Ridge(),\n",
        "        \"Decision Tree\": DecisionTreeRegressor(),\n",
        "        \"SVR\": SVR(),\n",
        "        \"KNN\": KNeighborsRegressor(),\n",
        "        \"Random Forest\": RandomForestRegressor(),\n",
        "        \"Gradient Boost\": GradientBoostingRegressor(),\n",
        "        \"Ada Boost\": AdaBoostRegressor(),\n",
        "        \"XG Boost\": XGBRegressor()\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for name, model in models.items():\n",
        "        scores = cross_val_score(\n",
        "            model, X_train, y_train, cv=folds, scoring=\"r2\"\n",
        "        )\n",
        "        results.append([name, scores.mean(), scores.std()])\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        results, columns=[\"Model Name\", \"CV Mean R2\", \"CV STD\"]).sort_values(\"CV Mean R2\", ascending=False)\n",
        "\n",
        "def hyperparameter_tuning(X_train, y_train, folds=5):\n",
        "    tuning_config = {\n",
        "        \"XGBoost\": {\n",
        "            \"model\": XGBRegressor(),\n",
        "            \"params\": {\n",
        "                \"eta\": [0.1, 0.2, 0.3],\n",
        "                \"max_depth\": [3, 5, 7],\n",
        "                \"gamma\": [0, 10, 20],\n",
        "                \"reg_lambda\": [0, 1]\n",
        "            }\n",
        "        },\n",
        "        \"Random Forest\": {\n",
        "            \"model\": RandomForestRegressor(),\n",
        "            \"params\": {\n",
        "                \"max_depth\": [5, 10, 15],\n",
        "                \"max_features\": [\"sqrt\", \"log2\", 3, 4]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    best_models = {}\n",
        "\n",
        "    for name, cfg in tuning_config.items():\n",
        "        grid = GridSearchCV(\n",
        "            cfg[\"model\"],\n",
        "            cfg[\"params\"],\n",
        "            cv=folds,\n",
        "            scoring=\"r2\",\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        grid.fit(X_train, y_train)\n",
        "\n",
        "        best_models[name] = grid.best_estimator_\n",
        "\n",
        "    return best_models\n",
        "\n",
        "def post_tuning_cv(best_models, X_train, y_train, folds=5):\n",
        "    results = []\n",
        "\n",
        "    for name, model in best_models.items():\n",
        "        scores = cross_val_score(\n",
        "            model, X_train, y_train, cv=folds, scoring=\"r2\"\n",
        "        )\n",
        "        results.append([name, scores.mean(), scores.std()])\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        results, columns=[\"Model Name\", \"CV Mean R2\", \"CV STD\"]).sort_values(\"CV Mean R2\", ascending=False)\n",
        "\n",
        "def final_test_evaluation(best_model, X_train, X_test, y_train, y_test):\n",
        "    best_model.fit(X_train, y_train)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    return rmse, r2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f15f3061",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f15f3061",
        "outputId": "9bfa7f7a-ce2e-4e2a-e8ee-062459e7159e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numerical EDA Report:\n",
            "                             Feature  Minimum  Maximum         Mean  Median  \\\n",
            "0                         Patient_ID      1.0   5500.0  2750.500000  2750.5   \n",
            "1                                age     18.0     90.0    53.872000    54.0   \n",
            "2                                bmi     15.0     40.9    28.170818    28.4   \n",
            "3                        systolic_bp    108.0    192.0   147.248182   147.0   \n",
            "4                       diastolic_bp     64.0    120.0    95.756727    96.0   \n",
            "5                  cholesterol_mg_dl    147.0    331.0   239.684182   240.0   \n",
            "6                 resting_heart_rate     48.0     92.0    74.075091    74.0   \n",
            "7                        daily_steps    500.0  16793.0  5902.929455  5460.0   \n",
            "8                       stress_level      1.0     10.0     4.907091     5.0   \n",
            "9   physical_activity_hours_per_week      0.0     12.9     3.299364     2.6   \n",
            "10                       sleep_hours      4.0     10.0     6.869364     6.9   \n",
            "11                diet_quality_score      1.0     10.0     5.162909     5.0   \n",
            "12            alcohol_units_per_week      0.0     29.2     3.782200     2.8   \n",
            "13          heart_disease_risk_score      0.0    100.0    37.540455    36.7   \n",
            "\n",
            "     Mode      25%      75%     IQR  Standard Deviation  Skewness  Kurtosis  \\\n",
            "0     1.0  1375.75  4125.25  2749.5         1587.857571  0.000000 -1.200000   \n",
            "1    54.0    36.00    72.00    36.0           21.196017  0.001834 -1.198188   \n",
            "2    29.0    25.20    31.10     5.9            4.189877 -0.122436 -0.385603   \n",
            "3   147.0   138.00   156.00    18.0           13.222701  0.044022 -0.345763   \n",
            "4    93.0    89.00   102.00    13.0            9.451559  0.012264 -0.282876   \n",
            "5   231.0   220.00   260.00    40.0           28.570177 -0.049690 -0.321708   \n",
            "6    74.0    70.00    79.00     9.0            6.392166 -0.284669 -0.112916   \n",
            "7   500.0  3428.00  7772.00  4344.0         3041.084590  0.641632 -0.317198   \n",
            "8     4.0     3.00     7.00     4.0            2.298173  0.227218 -0.691810   \n",
            "9     0.0     1.20     4.90     3.7            2.672457  0.840968 -0.072160   \n",
            "10    6.8     6.20     7.60     1.4            1.091263 -0.152763 -0.119172   \n",
            "11    4.0     3.00     7.00     4.0            2.286134  0.051647 -0.860156   \n",
            "12    0.5     1.20     5.30     4.1            3.515594  1.881418  5.559613   \n",
            "13    0.0    18.40    55.50    37.1           24.287026  0.212386 -0.747530   \n",
            "\n",
            "   Outlier Comment  \n",
            "0      No Outliers  \n",
            "1      No Outliers  \n",
            "2     Has Outliers  \n",
            "3     Has Outliers  \n",
            "4     Has Outliers  \n",
            "5     Has Outliers  \n",
            "6     Has Outliers  \n",
            "7     Has Outliers  \n",
            "8      No Outliers  \n",
            "9     Has Outliers  \n",
            "10    Has Outliers  \n",
            "11     No Outliers  \n",
            "12    Has Outliers  \n",
            "13     No Outliers  \n",
            "\n",
            "Categorical Summary:\n",
            "                        Feature  Unique Values Most Frequent  Missing Values\n",
            "0                smoking_status              3         Never               0\n",
            "1  family_history_heart_disease              2            No               0\n",
            "2                 risk_category              3        Medium               0\n",
            "\n",
            "Baseline Model Comparison:\n",
            "          Model Name       RMSE  R2 Score\n",
            "9           XG Boost   3.851508  0.975083\n",
            "7     Gradient Boost   3.986664  0.973304\n",
            "6      Random Forest   4.377311  0.967815\n",
            "2              Ridge   4.415342  0.967254\n",
            "0  Linear Regression   4.415375  0.967253\n",
            "1              Lasso   5.384683  0.951297\n",
            "8          Ada Boost   6.230361  0.934798\n",
            "3      Decision Tree   6.325504  0.932791\n",
            "5                KNN  21.678617  0.210599\n",
            "4                SVR  21.756612  0.204909\n",
            "\n",
            "Cross Validation Results (Before Tuning):\n",
            "          Model Name  CV Mean R2    CV STD\n",
            "9           XG Boost    0.975344  0.002563\n",
            "7     Gradient Boost    0.973150  0.003237\n",
            "0  Linear Regression    0.968671  0.004311\n",
            "2              Ridge    0.968671  0.004308\n",
            "6      Random Forest    0.967263  0.004184\n",
            "1              Lasso    0.951650  0.004384\n",
            "3      Decision Tree    0.933076  0.008744\n",
            "8          Ada Boost    0.930665  0.005921\n",
            "4                SVR    0.248009  0.030229\n",
            "5                KNN    0.197727  0.027751\n",
            "\n",
            "Cross Validation Results (After Tuning):\n",
            "      Model Name  CV Mean R2    CV STD\n",
            "0        XGBoost    0.978883  0.002227\n",
            "1  Random Forest    0.966210  0.002621\n",
            "\n",
            "Final Test Performance:\n",
            "Best Model : XGBoost\n",
            "RMSE       : 3.5053127870668077\n",
            "R2 Score   : 0.9793610316192439\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "DATA_URL = \"https://raw.githubusercontent.com/chandanc5525/CardioVascularRisk_AssessmentModel/refs/heads/main/data/raw/cardiovascular_risk_dataset.csv\"\n",
        "TARGET_COL = \"heart_disease_risk_score\"\n",
        "\n",
        "def main():\n",
        "    logging.info(\"ML Pipeline Started\")\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 1: Data Ingestion\n",
        "    # --------------------------------\n",
        "    df = data_ingestion(DATA_URL)\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 2: Data Exploration (EDA)\n",
        "    # --------------------------------\n",
        "    numerical_report = data_exploration(df)\n",
        "    categorical_report = categorical_summary(df)\n",
        "\n",
        "    print(\"\\nNumerical EDA Report:\")\n",
        "    print(numerical_report)\n",
        "\n",
        "    print(\"\\nCategorical Summary:\")\n",
        "    print(categorical_report)\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 3: Train–Test Split (ONCE)\n",
        "    # --------------------------------\n",
        "    X_train, X_test, y_train, y_test = split_data(\n",
        "        data=df,\n",
        "        target_col=TARGET_COL,\n",
        "        test_size=0.3,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    logging.info(\"Train–Test split completed\")\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 4: Baseline Model Comparison\n",
        "    # --------------------------------\n",
        "\n",
        "    X_train, X_test, encoders = encode_categorical(X_train, X_test)\n",
        "\n",
        "    baseline_results = compare_models(\n",
        "        X_train, X_test, y_train, y_test\n",
        "    )\n",
        "\n",
        "    print(\"\\nBaseline Model Comparison:\")\n",
        "    print(baseline_results)\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 5: Cross Validation (TRAIN ONLY)\n",
        "    # --------------------------------\n",
        "    cv_results = k_fold_cv(\n",
        "        X_train, y_train, folds=10\n",
        "    )\n",
        "\n",
        "    print(\"\\nCross Validation Results (Before Tuning):\")\n",
        "    print(cv_results)\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 6: Hyperparameter Tuning\n",
        "    # (TRAIN ONLY)\n",
        "    # --------------------------------\n",
        "    best_models = hyperparameter_tuning(\n",
        "        X_train, y_train, folds=5\n",
        "    )\n",
        "\n",
        "    logging.info(\"Hyperparameter tuning completed\")\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 7: Post-Tuning Cross Validation\n",
        "    # --------------------------------\n",
        "    post_cv_results = post_tuning_cv(\n",
        "        best_models, X_train, y_train, folds=5\n",
        "    )\n",
        "\n",
        "    print(\"\\nCross Validation Results (After Tuning):\")\n",
        "    print(post_cv_results)\n",
        "\n",
        "    # --------------------------------\n",
        "    # Step 8: Final Test Evaluation\n",
        "    # (TEST USED ONLY ONCE)\n",
        "    # --------------------------------\n",
        "    best_model_name = post_cv_results.iloc[0][\"Model Name\"]\n",
        "    best_model = best_models[best_model_name]\n",
        "\n",
        "    final_rmse, final_r2 = final_test_evaluation(\n",
        "        best_model, X_train, X_test, y_train, y_test\n",
        "    )\n",
        "\n",
        "    print(\"\\nFinal Test Performance:\")\n",
        "    print(f\"Best Model : {best_model_name}\")\n",
        "    print(f\"RMSE       : {final_rmse}\")\n",
        "    print(f\"R2 Score   : {final_r2}\")\n",
        "\n",
        "    logging.info(\"ML Pipeline Completed Successfully\")\n",
        "\n",
        "    return best_model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "CardioVascularRisk_AssessmentModel (3.13.12)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}